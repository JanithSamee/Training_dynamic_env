{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d0d0be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "feef08c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "# device=\"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "59ebf216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          time                                              chair  \\\n",
      "0  00:00.00000  [[-0.1140332378, -1.0363261758, 0.0844578892, ...   \n",
      "1  00:00.08103  [[-0.1087164686, -1.0356720574, 0.0847318111, ...   \n",
      "2  00:00.15946  [[-0.1033996995, -1.035017939, 0.085005733, 1....   \n",
      "3  00:00.23964  [[-0.09808293030000001, -1.0343638205, 0.08527...   \n",
      "4  00:00.31915  [[-0.09276616110000001, -1.0337097021, 0.08555...   \n",
      "\n",
      "                                               stool  \\\n",
      "0  [[2.1505855001, -1.4536903501, 0.1369566768, 1...   \n",
      "1  [[2.1473772297, -1.4468101854, 0.1367251761, 1...   \n",
      "2  [[2.1441689593, -1.4399300207, 0.1364936754000...   \n",
      "3  [[2.1409606889, -1.4330498561, 0.1362621746, 1...   \n",
      "4  [[2.1377524185, -1.4261696914, 0.1360306739, 1...   \n",
      "\n",
      "                                               table  \\\n",
      "0  [[0.1156135214, -2.2455869696, 0.1178784221, 1...   \n",
      "1  [[0.1152638103, -2.2443210638, 0.117856133, 1....   \n",
      "2  [[0.11491409920000001, -2.243055158, 0.1178338...   \n",
      "3  [[0.114564388, -2.2417892522, 0.1178115547, 1....   \n",
      "4  [[0.1142146769, -2.2405233464, 0.1177892655, 1...   \n",
      "\n",
      "                                                wall  \n",
      "0  [[0.6850594638, -4.899301481, 0.11792199310000...  \n",
      "1  [[0.6831968255, -4.8999852361, 0.1179998067, 3...  \n",
      "2  [[0.6813341873000001, -4.9006689912, 0.1180776...  \n",
      "3  [[0.6794715490000001, -4.9013527463, 0.1181554...  \n",
      "4  [[0.6776089108000001, -4.9020365014, 0.1182332...  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data=[]\n",
    "\n",
    "# data_file = './labels.json'\n",
    "data_file = './full_dataset/converted.json'\n",
    "\n",
    "using = \"pandas\"\n",
    "\n",
    "\n",
    "if(using==\"json\"):\n",
    "    # Load JSON data from the file\n",
    "    with open(data_file) as f:\n",
    "        data = json.load(f)\n",
    "    print(data[1]['time'])\n",
    "else:\n",
    "    data =pd.read_json(data_file)\n",
    "    print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9c7ca7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Mis-aligend Files\n",
    "for item in [\"chair\",\"stool\",\"table\",\"wall\"]:\n",
    "    for index,i in enumerate(data[item]):\n",
    "        if type(i)== dict:\n",
    "            data=data.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "30d58128",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in [\"chair\",\"stool\",\"table\",\"wall\"]:\n",
    "    for index,i in enumerate(data[item]):\n",
    "        if type(i)== dict:\n",
    "            print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7ddcb368",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m---> 14\u001b[0m \u001b[43mreadPCDFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m00:00.08103\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[163], line 12\u001b[0m, in \u001b[0;36mreadPCDFile\u001b[0;34m(fileName)\u001b[0m\n\u001b[1;32m     10\u001b[0m output\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39masanyarray(point_cloud\u001b[38;5;241m.\u001b[39mpoints))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     11\u001b[0m output\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(output, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1600\u001b[39m \u001b[38;5;241m-\u001b[39m output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)))\n\u001b[0;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "def readPCDFile(fileName):\n",
    "    fileName =fileName.replace(\":\",\"_\")\n",
    "#     pcd_path = f\"data_set/{fileName}.pcd\"\n",
    "    pcd_path = f\"full_dataset/pcd/{fileName}.pcd\"\n",
    "    point_cloud = o3d.io.read_point_cloud(pcd_path)\n",
    "    point_cloud = point_cloud.voxel_down_sample(voxel_size=0.086)\n",
    "    output=torch.from_numpy(np.asanyarray(point_cloud.points)).float()\n",
    "    output=torch.nn.functional.pad(output, (0, 0, 0, 1600 - output.size(0)))\n",
    "    output = output.to(device=device)\n",
    "    return output\n",
    "readPCDFile(\"00:00.08103\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f4165285",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.labels=data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx] if using==\"json\" else self.labels.iloc[idx]\n",
    "        point_cloud_data = readPCDFile(label['time'])\n",
    "        label_data=torch.tensor(label['chair'],device=device)\n",
    "        return [point_cloud_data, label_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "eeb2a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(data=data)\n",
    "dataset_loader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ff62fa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 32.1687, -18.3864,   3.2417],\n",
       "         [ -0.5897,   2.7161,   0.2432],\n",
       "         [ -0.1999,   3.2694,   0.2866],\n",
       "         ...,\n",
       "         [  0.0000,   0.0000,   0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000]], device='cuda:0'),\n",
       " tensor([[-0.1140, -1.0363,  0.0845,  1.8055,  1.1400,  0.4269,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 1.2384, -3.4363,  0.1242,  1.2163,  1.3069,  0.7050,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 3.2114, -3.2485,  0.1857,  0.9632,  1.1087,  0.9266,  0.0000,  0.0000,\n",
       "          48.5323],\n",
       "         [ 5.4827,  0.1195,  0.1603,  1.7691,  1.9000,  0.9465,  0.0000,  0.0000,\n",
       "           0.0000]], device='cuda:0')]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_loader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dc5e2850",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        self.model=nn.Sequential(\n",
    "#           # Define convolutional layers\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.MaxPool1d(kernel_size=16, stride=2),\n",
    "            nn.Conv1d(in_channels=16, out_channels=16, kernel_size=4, padding=1),\n",
    "            nn.Linear(792,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(16,1),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.prob=nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,32),\n",
    "            nn.Linear(32,10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.boxes=nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,32),\n",
    "            nn.Linear(32,90)\n",
    "        )\n",
    "       \n",
    "    def forward(self,x):\n",
    "        \n",
    "        base = self.model(x)\n",
    "        _base = base.clone()\n",
    "        prob = self.prob(base)\n",
    "        boxes = self.boxes(_base).view(-1, 10,9)\n",
    "        return prob,boxes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d379cb12",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mNeuralNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "File \u001b[0;32m~/notebook/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/notebook/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/notebook/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/notebook/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/notebook/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "criterion_prob = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b98e225c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[157], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m total_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, _data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(i\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m15\u001b[39m):\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/notebook/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/notebook/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/notebook/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/notebook/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[142], line 11\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     10\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx] \u001b[38;5;28;01mif\u001b[39;00m using\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[0;32m---> 11\u001b[0m     point_cloud_data \u001b[38;5;241m=\u001b[39m \u001b[43mreadPCDFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     label_data\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(label[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchair\u001b[39m\u001b[38;5;124m'\u001b[39m],device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [point_cloud_data, label_data]\n",
      "Cell \u001b[0;32mIn[141], line 12\u001b[0m, in \u001b[0;36mreadPCDFile\u001b[0;34m(fileName)\u001b[0m\n\u001b[1;32m     10\u001b[0m output\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39masanyarray(point_cloud\u001b[38;5;241m.\u001b[39mpoints))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     11\u001b[0m output\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(output, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1600\u001b[39m \u001b[38;5;241m-\u001b[39m output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)))\n\u001b[0;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def pad_labels(label, max_len=10):\n",
    "    if len(label[0])>0 :\n",
    "        pad_width=max_len-len(label[0])\n",
    "        padded_label = torch.nn.functional.pad(label, (0, 0, 0,pad_width,0,0))\n",
    "        return padded_label\n",
    "    else:\n",
    "        return torch.zeros(1,10,9,device=device)\n",
    "\n",
    "loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for i, _data in enumerate(dataset_loader, 0):\n",
    "        if(i>15):\n",
    "            break\n",
    "        try:\n",
    "            inputs, labels = _data\n",
    "            optimizer.zero_grad()\n",
    "            prob, boxes = model(inputs.transpose(1, 2))\n",
    "            loss = criterion(boxes, pad_labels(labels.float()))\n",
    "#             prob_test = np.zeros((1, 10))\n",
    "#             prob_test[0, :len(labels[0])] = 1 / (len(labels[0]) if len(labels[0])>0 else 1 )\n",
    "#             loss_prob = criterion_prob(prob, torch.tensor(prob_test, device=device))\n",
    "#             total_loss =  loss_prob\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        except:\n",
    "            print(\"Exception Occured at \"+i)\n",
    "            pass\n",
    "        # Update statistics\n",
    "       \n",
    "        \n",
    "    if epoch % 100 == 0:  # Print every 10 mini-batches\n",
    "        print('[%d / 100] loss: %.3f' % (epoch + 1, running_loss / 100), end=\"\\r\", flush=True)\n",
    "#             running_loss = 0.0\n",
    "\n",
    "    loss_values.append(running_loss/100)\n",
    "\n",
    "# Plot the loss function\n",
    "plt.plot(loss_values, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "39056d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[5.4256e-01, 4.5744e-01, 7.8974e-39, 1.4728e-42, 1.4013e-45, 8.3489e-42,\n",
      "         1.5204e-42, 4.3277e-38, 1.2766e-40, 3.4013e-40]], device='cuda:0'), tensor([[[ 5.5844e-01, -5.4920e-01,  3.4757e-01,  1.6946e+00,  1.0740e+00,\n",
      "           1.0163e+00,  1.1024e-01, -4.3087e-02,  9.6505e+01],\n",
      "         [ 1.5524e+00, -1.2016e+00,  2.3682e-01,  5.9967e-01,  8.9543e-01,\n",
      "          -5.3809e-02, -1.3164e-01, -4.0612e-01,  1.1910e+02],\n",
      "         [ 5.6126e-01,  1.9396e+00, -2.3728e-02,  1.2576e+00,  1.1388e+00,\n",
      "           1.1933e+00,  3.2872e-01,  3.2016e-01, -1.0077e+01],\n",
      "         [-8.3124e-01,  1.0617e-01,  4.0135e-01,  4.2199e-01, -2.0902e-01,\n",
      "           6.3450e-01, -8.6333e-03,  5.9295e-02,  9.0797e-02],\n",
      "         [ 4.3726e-02,  2.3291e-01, -4.1910e-01,  1.2162e-01,  6.1911e-02,\n",
      "           6.1448e-01, -2.0163e-01, -4.9227e-01,  3.3331e-02],\n",
      "         [ 6.4744e-02, -3.7859e-01,  2.5120e-01, -4.2707e-01, -1.0397e-01,\n",
      "          -1.1497e-01,  1.2403e-02,  1.7447e-02,  1.9050e-01],\n",
      "         [-5.5576e-04,  1.0022e-01,  4.3695e-01,  1.2134e-01,  7.3248e-02,\n",
      "           4.3991e-01, -1.1208e-01, -3.5345e-01, -2.5118e-01],\n",
      "         [ 5.2274e-01,  1.1354e-01, -6.0037e-01,  1.8777e-01, -4.5688e-01,\n",
      "          -1.1761e-01,  3.4391e-03, -1.9993e-01, -2.8959e-01],\n",
      "         [ 1.4154e-01, -1.8351e-01,  6.2438e-02,  3.7151e-01,  5.6898e-02,\n",
      "           1.1471e-01, -1.4170e-01, -5.3589e-01, -8.6699e-02],\n",
      "         [-2.1475e-01,  2.0646e-01,  5.1986e-02,  2.0766e-01,  4.0601e-01,\n",
      "           7.1384e-02,  3.9928e-01, -1.3670e-01, -7.8594e-02]]],\n",
      "       device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = model(readPCDFile(\"00:07.99279\").unsqueeze(0).transpose(1,2))\n",
    "    print(prediction)\n",
    "# print(readPCDFile(\"00:07.99279\").unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "92fe721d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Conv1d(128,16,kernel_size=3)\n",
    "input = torch.randn(128,3)\n",
    "output = m(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2b9fd747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1460, 1, 3]) torch.Size([1460, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LiDARConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LiDARConvNet, self).__init__()\n",
    "        \n",
    "        # Define convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=16, kernel_size=3)\n",
    "#         self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "#         # Define max pooling layer\n",
    "#         self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "#         # Define fully connected layers\n",
    "#         self.fc1 = nn.Linear(64 * 365, 128)  # Adjusted based on the expected size after pooling\n",
    "#         self.fc2 = nn.Linear(128, 64)\n",
    "#         self.fc3 = nn.Linear(64, 10)  # Example output size\n",
    "        \n",
    "#         # Define activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply convolutional and pooling layers\n",
    "        x = self.relu(self.conv1(x))\n",
    "#         x = self.pool(x)\n",
    "#         x = self.relu(self.conv2(x))\n",
    "#         x = self.pool(x)\n",
    "#         x = self.relu(self.conv3(x))\n",
    "#         x = self.pool(x)\n",
    "        \n",
    "#         # Flatten the output for fully connected layers\n",
    "#         x = x.view(-1, 64 * 365)\n",
    "        \n",
    "#         # Apply fully connected layers\n",
    "#         x = self.relu(self.fc1(x))\n",
    "#         x = self.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "lidar_data = torch.randn( 1460, 3)  # Assuming you have 1460 points in your LiDAR point cloud\n",
    "# conv_net = LiDARConvNet()\n",
    "# output = conv_net(lidar_data.unsqueeze(1).transpose(1, 2))  # Transpose to (batch_size, channels, sequence_length)\n",
    "print(lidar_data.unsqueeze(1).shape,lidar_data.unsqueeze(1).transpose(1,2).shape)  # Output shape would be (batch_size, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c4ea44f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0001"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([0.0822, 0.0629, 0.1309, 0.0699, 0.1266, 0.0716, 0.1137, 0.0919, 0.1356,\n",
    "         0.1148])\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b650b379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a>0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0c19e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.zeros((1, 10))\n",
    "arr[0, :4] = 1 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "4a2747b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6., dtype=torch.float64)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.tensor(np.ones((1,10)))\n",
    "torch.sum(target-arr*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e18c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_test = np.zeros((1, 10))\n",
    "prob_test[0, :0] = 1 / 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "841f36cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bd0e489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'A':[1,2,4,6],\"B\":[1,2,4,5]}\n",
    "df =pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bcf0f28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B\n",
       "0  1  1\n",
       "2  4  4\n",
       "3  6  5"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8e567a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B\n",
       "0  1  1\n",
       "1  2  2\n",
       "2  4  4\n",
       "3  6  5"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e0d500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
